"""
LazyAI Studio - Ultra Performance Edition
è¶…é«˜æ€§èƒ½ç‰ˆæœ¬ - æè‡´ä¼˜åŒ–å†…å­˜å’ŒCPUä½¿ç”¨

ä¼˜åŒ–ç‰¹æ€§:
- ç§»é™¤æ‰€æœ‰éå¿…è¦æœåŠ¡å’Œä¸­é—´ä»¶
- æ‡’åŠ è½½æ‰€æœ‰ç»„ä»¶
- æœ€å°åŒ–å†…å­˜å ç”¨
- å‡å°‘CPUå‘¨æœŸ
- ä¼˜åŒ–å¯åŠ¨æ—¶é—´
"""

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
from typing import Optional
import gc
import os
import psutil

# åªå¯¼å…¥å¿…è¦çš„é…ç½®
from app.core.config import API_PREFIX, DEBUG, LOG_LEVEL, ENVIRONMENT

# å»¶è¿Ÿå¯¼å…¥ä¼˜åŒ– - åªåœ¨éœ€è¦æ—¶å¯¼å…¥
_database_service = None
_logger = None

def get_logger():
    """å»¶è¿Ÿåˆå§‹åŒ–æ—¥å¿—"""
    global _logger
    if _logger is None:
        from app.core.logging import setup_logging
        _logger = setup_logging(LOG_LEVEL)
    return _logger

def get_database_service():
    """å»¶è¿Ÿåˆå§‹åŒ–æ•°æ®åº“æœåŠ¡"""
    global _database_service
    if _database_service is None:
        from app.core.database_service_lite import init_lite_database_service
        _database_service = init_lite_database_service(use_unified_db=True)
    return _database_service

@asynccontextmanager
async def lifespan(app: FastAPI):
    """è¶…è½»é‡çº§ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger = get_logger()
    logger.info("Initializing ultra-optimized application...")

    try:
        # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œé‡Šæ”¾å¯åŠ¨æ—¶çš„ä¸´æ—¶å¯¹è±¡
        gc.collect()

        # ç®€åŒ–å¯åŠ¨ä¿¡æ¯
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024

        startup_message = f"""
ğŸš€ LazyAI Studio (Ultra) - Memory: {memory_mb:.1f}MB
âš¡ æè‡´æ€§èƒ½æ¨¡å¼å¯åŠ¨å®Œæˆï¼
ğŸ“ http://localhost:8000
"""
        print(startup_message, flush=True)

    except Exception as e:
        logger.error(f"Startup error: {e}")
        raise

    yield

    # æ¸…ç†èµ„æº
    logger = get_logger()
    logger.info("Shutting down ultra application...")

    if _database_service:
        _database_service.close()

    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()
    print("âœ… Ultra service closed\n", flush=True)

# åˆ›å»ºæœ€å°åŒ–çš„ FastAPI åº”ç”¨
app = FastAPI(
    title="LazyAI Studio (Ultra)",
    description="è¶…é«˜æ€§èƒ½ç‰ˆ - æè‡´ä¼˜åŒ–å†…å­˜å’ŒCPUä½¿ç”¨",
    version="1.2.0-ultra",
    debug=DEBUG,
    lifespan=lifespan,
    # ç¦ç”¨è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆä»¥èŠ‚çœå†…å­˜
    docs_url="/docs" if DEBUG else None,
    redoc_url="/redoc" if DEBUG else None,
    openapi_url="/openapi.json" if DEBUG else None,
)

# ç®€åŒ–çš„å¼‚å¸¸å¤„ç†å™¨
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger = get_logger()
    logger.error(f"Error in {request.method} {request.url}: {exc}")
    return JSONResponse(
        status_code=500,
        content={"success": False, "message": "Internal server error"}
    )

# æœ€å°åŒ–CORSé…ç½®
if ENVIRONMENT == "local":
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["GET", "POST", "PUT", "DELETE"],
        allow_headers=["Content-Type", "Authorization"],
    )
else:
    # ç”Ÿäº§ç¯å¢ƒæ›´ä¸¥æ ¼çš„CORSé…ç½®
    from app.core.config import CORS_ORIGINS, CORS_ALLOW_CREDENTIALS
    app.add_middleware(
        CORSMiddleware,
        allow_origins=CORS_ORIGINS,
        allow_credentials=CORS_ALLOW_CREDENTIALS,
        allow_methods=["GET", "POST", "PUT", "DELETE"],
        allow_headers=["Content-Type", "Authorization"],
    )

# å»¶è¿ŸåŠ è½½è·¯ç”±
@app.get("/api/models")
async def get_models():
    """å»¶è¿ŸåŠ è½½æ¨¡å‹æ•°æ®"""
    db_service = get_database_service()
    models = db_service.get_models_data()
    return {"success": True, "data": models, "total": len(models)}

@app.get("/api/models/{slug}")
async def get_model(slug: str):
    """è·å–å•ä¸ªæ¨¡å‹"""
    db_service = get_database_service()
    model = db_service.get_model_by_slug(slug)
    if model:
        return {"success": True, "data": model}
    return {"success": False, "message": "Model not found"}

@app.get("/api/models/group/{group}")
async def get_models_by_group(group: str):
    """æŒ‰ç»„è·å–æ¨¡å‹"""
    db_service = get_database_service()
    models = db_service.get_models_by_group(group)
    return {"success": True, "data": models, "total": len(models)}

@app.post("/api/models/refresh")
async def refresh_models():
    """åˆ·æ–°æ¨¡å‹ç¼“å­˜"""
    db_service = get_database_service()
    result = db_service.refresh_models_cache()

    # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
    gc.collect()

    return {"success": True, "data": result}

@app.get("/api/system/status")
async def system_status():
    """ç³»ç»ŸçŠ¶æ€"""
    process = psutil.Process()
    memory_info = process.memory_info()

    db_service = get_database_service()
    db_status = db_service.get_status()

    return {
        "success": True,
        "data": {
            "version": "1.2.0-ultra",
            "mode": "ultra_performance",
            "memory_mb": round(memory_info.rss / 1024 / 1024, 2),
            "cpu_percent": process.cpu_percent(),
            "database": db_status,
            "optimizations": [
                "lazy_loading",
                "minimal_imports",
                "gc_optimization",
                "memory_pooling",
                "no_file_watching",
                "simplified_middleware"
            ]
        }
    }

@app.post("/api/system/gc")
async def force_garbage_collection():
    """æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶"""
    collected = gc.collect()
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024

    return {
        "success": True,
        "data": {
            "collected_objects": collected,
            "memory_mb": round(memory_mb, 2)
        }
    }

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    return {"status": "healthy", "mode": "ultra"}

@app.get("/api/health")
async def api_health_check():
    return await health_check()

# æ ¹è·¯å¾„ä¿¡æ¯
@app.get("/")
async def root():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024

    return {
        "message": "LazyAI Studio API (Ultra Performance)",
        "organization": "LazyGophers",
        "version": "1.2.0-ultra",
        "mode": "ultra_performance",
        "memory_mb": round(memory_mb, 2),
        "features": [
            "æè‡´å†…å­˜ä¼˜åŒ–",
            "CPUä½¿ç”¨æœ€å°åŒ–",
            "æ‡’åŠ è½½æ¶æ„",
            "åƒåœ¾å›æ”¶ä¼˜åŒ–"
        ],
        "docs": "/docs" if DEBUG else "disabled"
    }

# å¦‚æœéœ€è¦å®Œæ•´APIï¼Œå¯ä»¥åŠ¨æ€åŠ è½½
@app.get("/api/load-full-features")
async def load_full_features():
    """åŠ¨æ€åŠ è½½å®Œæ•´åŠŸèƒ½ï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰"""
    try:
        # åŠ¨æ€å¯¼å…¥å®Œæ•´è·¯ç”±
        from app.routers import api_router
        app.include_router(api_router, prefix=API_PREFIX)

        return {
            "success": True,
            "message": "Full features loaded",
            "warning": "Memory usage will increase"
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Failed to load full features: {e}"
        }

# è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆå¦‚æœæ˜¯Linux/Unixç³»ç»Ÿï¼‰
try:
    if hasattr(os, 'nice'):
        # è®¾ç½®è¾ƒä½çš„è¿›ç¨‹ä¼˜å…ˆçº§ä»¥å‡å°‘CPUç«äº‰
        os.nice(5)
except:
    pass

# ä¼˜åŒ–åƒåœ¾å›æ”¶è®¾ç½®
gc.set_threshold(700, 10, 10)  # æ›´ä¿å®ˆçš„GCè®¾ç½®