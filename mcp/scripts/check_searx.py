#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜æ€§èƒ½ Searx å®ä¾‹å¯ç”¨æ€§æ£€æµ‹å™¨

è¿™ä¸ªè„šæœ¬ä¼šæ£€æµ‹æ‰€æœ‰é…ç½®çš„ Searx å®ä¾‹çš„å¯ç”¨æ€§ï¼Œå¹¶è‡ªåŠ¨æ›´æ–° config.yaml æ–‡ä»¶ã€‚
æ”¯æŒå¹¶å‘æ£€æµ‹ã€è¿›åº¦æ˜¾ç¤ºã€é…ç½®å¤‡ä»½ç­‰é«˜çº§åŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/check_searx.py
    python scripts/check_searx.py --concurrent 20 --timeout 5
    python scripts/check_searx.py --dry-run --verbose
"""

import argparse
import json
import logging
import os
import shutil
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import requests
import yaml
from requests.adapters import HTTPAdapter
from tqdm import tqdm
from urllib3.util.retry import Retry

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.tools.searx import search

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é»˜è®¤ Searx å®ä¾‹åˆ—è¡¨
DEFAULT_HOST_LIST = [
    "https://so.ddns-ip.net",
    "https://seek.nuer.cc",
    "https://sousuo.emoe.top",
    "https://searxng.ctbot.tech",
    "https://searxng.jethrowang.cn",
    "https://aimonitor.xiaocg.xyz",
    "https://search.fatgpt.cn",
    "https://searxng.narasaka.dev",
    "https://search.songai.icu",
    "https://searxng.ddaodan.cc",
    "https://sg.goyor.com",
    "https://search.infinityf4p.com",
    "https://s.yyy.earth",
    "https://ss.helper5210.top",
    "https://search.no-code.gdn",
    "https://search.corrently.cloud",
    "https://search.jakespeed.org",
    "https://searxng.fly2me.cc",
    "https://searxng.stardream.online",
    "https://search.lucathomas.de",
    "https://negativenull.com",
    "https://searx.yorgis.net",
    "https://search.mixel.cloud",
    "https://xng.huidaolasa.xyz",
    "https://searxng-pilot.jitera.app",
    "https://searxng.vyro.ai",
    "https://martechia.online",
    "https://search.chgr.cc",
    "https://websearch.nwt.de",
    "https://s.arson.pw",
    "https://s.gottsnack.net",
    "https://srx.zebralab.io",
    "https://search.the8.dev",
    "https://search.nicolasallemand.com",
    "https://search.aidoing.de",
    "https://search.f-ws.net",
    "https://searxng.ai.flagbit.de",
    "https://searxng.asudox.dev",
    "https://searxng.k3s.koski.co",
    "https://mfood3.hongquantrader.com",
    "https://searx.privhub.space",
    "https://search.muellers-software.org",
    "https://searxng.lmdr.io",
    "https://uwg8swww0o0cw4osg4okc4gs.phytertek.com",
    "https://searxng.sbbz-ilvesheim.de",
    "https://search.soulrend.net",
    "https://searxng.core.sciling.com",
    "https://searxng.springbokagency.com",
    "https://seachx.lunarfire.home64.de",
    "https://cari.aeenquran.id",
    "https://searx.work",
]


@dataclass
class CheckResult:
    """Searx å®ä¾‹æ£€æµ‹ç»“æœ"""
    host: str
    is_alive: bool
    response_time: Optional[float] = None
    error: Optional[str] = None
    timestamp: datetime = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()


class SearxChecker:
    """Searx å®ä¾‹å¯ç”¨æ€§æ£€æµ‹å™¨"""
    
    def __init__(
        self,
        timeout: int = 10,
        max_workers: int = 10,
        test_query: str = "test",
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_workers: æœ€å¤§å¹¶å‘æ•°
            test_query: æµ‹è¯•æŸ¥è¯¢å­—ç¬¦ä¸²
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        self.timeout = timeout
        self.max_workers = max_workers
        self.test_query = test_query
        self.verbose = verbose
        
        # é…ç½®æ—¥å¿—çº§åˆ«
        if verbose:
            logger.setLevel(logging.DEBUG)
            logging.getLogger().setLevel(logging.DEBUG)
        
        # åˆ›å»º HTTP ä¼šè¯
        self.session = self._create_session()
    
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºé…ç½®å¥½çš„ HTTP ä¼šè¯"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=2,
            backoff_factor=0.3,
            status_forcelist=[408, 429, 500, 502, 503, 504],
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # è®¾ç½®è¯·æ±‚å¤´
        session.headers.update({
            "User-Agent": "Searx-Checker/1.0",
            "Accept": "application/json",
        })
        
        return session
    
    def check_host_direct(self, host: str) -> CheckResult:
        """
        ç›´æ¥æ£€æµ‹å•ä¸ª Searx å®ä¾‹ï¼ˆä½¿ç”¨ HTTP è¯·æ±‚ï¼‰
        
        Args:
            host: Searx å®ä¾‹ URL
            
        Returns:
            æ£€æµ‹ç»“æœ
        """
        logger.debug(f"ç›´æ¥æ£€æµ‹ {host}")
        start_time = time.time()
        
        try:
            # æ„å»ºæœç´¢ URL
            search_url = f"{host.rstrip('/')}/search"
            params = {
                "q": self.test_query,
                "format": "json",
                "categories": "general",
                "pageno": 1
            }
            
            # å‘é€è¯·æ±‚
            response = self.session.get(
                search_url,
                params=params,
                timeout=self.timeout
            )
            
            # æ£€æŸ¥å“åº”
            response.raise_for_status()
            data = response.json()
            
            # éªŒè¯å“åº”æ ¼å¼
            if isinstance(data, dict) and "results" in data:
                response_time = time.time() - start_time
                logger.debug(f"âœ… {host} å¯ç”¨ (å“åº”æ—¶é—´: {response_time:.2f}s)")
                return CheckResult(
                    host=host,
                    is_alive=True,
                    response_time=response_time
                )
            else:
                logger.debug(f"âŒ {host} å“åº”æ ¼å¼æ— æ•ˆ")
                return CheckResult(
                    host=host,
                    is_alive=False,
                    error="Invalid response format"
                )
                
        except requests.exceptions.Timeout:
            logger.debug(f"â±ï¸ {host} è¶…æ—¶")
            return CheckResult(
                host=host,
                is_alive=False,
                error=f"Timeout after {self.timeout}s"
            )
        except requests.exceptions.ConnectionError as e:
            logger.debug(f"ğŸ”Œ {host} è¿æ¥å¤±è´¥: {e}")
            return CheckResult(
                host=host,
                is_alive=False,
                error=f"Connection error: {str(e)[:50]}"
            )
        except Exception as e:
            logger.debug(f"âŒ {host} æ£€æµ‹å¤±è´¥: {e}")
            return CheckResult(
                host=host,
                is_alive=False,
                error=f"Error: {str(e)[:50]}"
            )
    
    def check_host_via_tool(self, host: str) -> CheckResult:
        """
        é€šè¿‡é¡¹ç›®çš„ searx å·¥å…·æ£€æµ‹å•ä¸ªå®ä¾‹
        
        Args:
            host: Searx å®ä¾‹ URL
            
        Returns:
            æ£€æµ‹ç»“æœ
        """
        logger.debug(f"é€šè¿‡å·¥å…·æ£€æµ‹ {host}")
        start_time = time.time()
        
        # ä¸´æ—¶ä¿®æ”¹é…ç½®ä»¥æµ‹è¯•ç‰¹å®š host
        import src.config as config_module
        original_hosts = config_module._config.searx.searx_hosts if config_module._config else []
        
        try:
            # è®¾ç½®å•ä¸ª host è¿›è¡Œæµ‹è¯•
            if config_module._config:
                config_module._config.searx.searx_hosts = [host]
            
            # ä½¿ç”¨ search å‡½æ•°è¿›è¡Œæµ‹è¯•
            results = search(
                query=self.test_query,
                categories="general",
                page=1
            )
            
            # æ£€æŸ¥ç»“æœ
            if results and isinstance(results, dict) and "results" in results:
                response_time = time.time() - start_time
                logger.debug(f"âœ… {host} å¯ç”¨ (å“åº”æ—¶é—´: {response_time:.2f}s)")
                return CheckResult(
                    host=host,
                    is_alive=True,
                    response_time=response_time
                )
            else:
                logger.debug(f"âŒ {host} æ— æœ‰æ•ˆç»“æœ")
                return CheckResult(
                    host=host,
                    is_alive=False,
                    error="No valid results"
                )
                
        except Exception as e:
            logger.debug(f"âŒ {host} æ£€æµ‹å¤±è´¥: {e}")
            return CheckResult(
                host=host,
                is_alive=False,
                error=f"Error: {str(e)[:50]}"
            )
        finally:
            # æ¢å¤åŸå§‹é…ç½®
            if config_module._config:
                config_module._config.searx.searx_hosts = original_hosts
    
    def check_hosts_concurrent(
        self,
        hosts: List[str],
        use_tool: bool = False
    ) -> List[CheckResult]:
        """
        å¹¶å‘æ£€æµ‹å¤šä¸ª Searx å®ä¾‹
        
        Args:
            hosts: Searx å®ä¾‹ URL åˆ—è¡¨
            use_tool: æ˜¯å¦ä½¿ç”¨é¡¹ç›®å·¥å…·è¿›è¡Œæ£€æµ‹
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        check_func = self.check_host_via_tool if use_tool else self.check_host_direct
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ£€æµ‹
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_host = {
                executor.submit(check_func, host): host
                for host in hosts
            }
            
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
            with tqdm(
                total=len(hosts),
                desc="æ£€æµ‹ Searx å®ä¾‹",
                unit="host",
                ncols=100,
                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'
            ) as pbar:
                for future in as_completed(future_to_host):
                    result = future.result()
                    results.append(result)
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    status = "âœ…" if result.is_alive else "âŒ"
                    pbar.set_postfix_str(f"{status} {result.host[:30]}")
                    pbar.update(1)
        
        return results
    
    def print_summary(self, results: List[CheckResult]):
        """
        æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦
        
        Args:
            results: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        alive_results = [r for r in results if r.is_alive]
        dead_results = [r for r in results if not r.is_alive]
        
        print("\n" + "="*60)
        print("ğŸ“Š æ£€æµ‹ç»“æœç»Ÿè®¡")
        print("="*60)
        
        print(f"\nâœ… å¯ç”¨å®ä¾‹ ({len(alive_results)}/{len(results)}):")
        if alive_results:
            # æŒ‰å“åº”æ—¶é—´æ’åº
            alive_results.sort(key=lambda x: x.response_time or float('inf'))
            for i, result in enumerate(alive_results[:10], 1):
                time_str = f"{result.response_time:.2f}s" if result.response_time else "N/A"
                print(f"  {i:2d}. {result.host:40} [{time_str}]")
            if len(alive_results) > 10:
                print(f"  ... è¿˜æœ‰ {len(alive_results) - 10} ä¸ªå¯ç”¨å®ä¾‹")
        else:
            print("  ï¼ˆæ— å¯ç”¨å®ä¾‹ï¼‰")
        
        print(f"\nâŒ ä¸å¯ç”¨å®ä¾‹ ({len(dead_results)}/{len(results)}):")
        if dead_results:
            for i, result in enumerate(dead_results[:5], 1):
                error = result.error or "Unknown error"
                print(f"  {i:2d}. {result.host:40} - {error}")
            if len(dead_results) > 5:
                print(f"  ... è¿˜æœ‰ {len(dead_results) - 5} ä¸ªä¸å¯ç”¨å®ä¾‹")
        else:
            print("  ï¼ˆæ‰€æœ‰å®ä¾‹éƒ½å¯ç”¨ï¼‰")
        
        # æ€§èƒ½ç»Ÿè®¡
        if alive_results:
            avg_time = sum(r.response_time for r in alive_results if r.response_time) / len(alive_results)
            min_time = min(r.response_time for r in alive_results if r.response_time)
            max_time = max(r.response_time for r in alive_results if r.response_time)
            
            print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
            print(f"  å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}s")
            print(f"  æœ€å¿«å“åº”æ—¶é—´: {min_time:.2f}s")
            print(f"  æœ€æ…¢å“åº”æ—¶é—´: {max_time:.2f}s")
        
        print("\n" + "="*60)


class ConfigManager:
    """é…ç½®æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = Path(config_path)
        self.backup_dir = Path("backups")
    
    def backup_config(self) -> Optional[Path]:
        """
        å¤‡ä»½å½“å‰é…ç½®æ–‡ä»¶
        
        Returns:
            å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤‡ä»½å¤±è´¥åˆ™è¿”å› None
        """
        if not self.config_path.exists():
            logger.warning(f"é…ç½®æ–‡ä»¶ {self.config_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½")
            return None
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self.backup_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"config_{timestamp}.yaml"
        
        try:
            shutil.copy2(self.config_path, backup_path)
            logger.info(f"âœ… é…ç½®æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_path}")
            return backup_path
        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def load_config(self) -> Dict:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Returns:
            é…ç½®å­—å…¸
        """
        if not self.config_path.exists():
            logger.warning(f"é…ç½®æ–‡ä»¶ {self.config_path} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return {}
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f) or {}
                logger.debug(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {self.config_path}")
                return config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def update_searx_hosts(
        self,
        hosts: List[str],
        dry_run: bool = False
    ) -> bool:
        """
        æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„ searx_hosts å­—æ®µ
        
        Args:
            hosts: æ–°çš„ Searx å®ä¾‹åˆ—è¡¨
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œï¼ˆä¸å®é™…å†™å…¥æ–‡ä»¶ï¼‰
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            # åŠ è½½ç°æœ‰é…ç½®
            config = self.load_config()
            
            # æ›´æ–° searx_hosts å­—æ®µ
            old_hosts = config.get('searx_hosts', [])
            config['searx_hosts'] = hosts
            
            # æ˜¾ç¤ºå˜æ›´
            logger.info(f"ğŸ“ é…ç½®æ›´æ–°:")
            logger.info(f"  åŸæœ‰ {len(old_hosts)} ä¸ªå®ä¾‹")
            logger.info(f"  æ›´æ–°ä¸º {len(hosts)} ä¸ªå¯ç”¨å®ä¾‹")
            
            if dry_run:
                logger.info("ğŸ” æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼Œä¸ä¼šå®é™…æ›´æ–°é…ç½®æ–‡ä»¶")
                print("\nå°†è¦å†™å…¥çš„é…ç½®:")
                print(yaml.dump({'searx_hosts': hosts}, allow_unicode=True, default_flow_style=False)[:500])
                return True
            
            # å¤‡ä»½åŸé…ç½®
            backup_path = self.backup_config()
            
            # å†™å…¥æ–°é…ç½®ï¼ˆåŸå­æ“ä½œï¼‰
            temp_path = self.config_path.with_suffix('.tmp')
            try:
                with open(temp_path, 'w', encoding='utf-8') as f:
                    yaml.dump(
                        config,
                        f,
                        allow_unicode=True,
                        default_flow_style=False,
                        sort_keys=False
                    )
                
                # åŸå­æ›¿æ¢
                temp_path.replace(self.config_path)
                logger.info(f"âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°: {self.config_path}")
                return True
                
            except Exception as e:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_path.exists():
                    temp_path.unlink()
                raise e
                
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æ£€æµ‹ Searx å®ä¾‹å¯ç”¨æ€§å¹¶æ›´æ–°é…ç½®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                           # ä½¿ç”¨é»˜è®¤å‚æ•°æ£€æµ‹
  %(prog)s --concurrent 20           # ä½¿ç”¨ 20 ä¸ªå¹¶å‘è¿æ¥
  %(prog)s --timeout 5               # è®¾ç½® 5 ç§’è¶…æ—¶
  %(prog)s --dry-run                 # æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸æ›´æ–°é…ç½®
  %(prog)s --use-tool                # ä½¿ç”¨é¡¹ç›® searx å·¥å…·æ£€æµ‹
  %(prog)s --host-file hosts.txt     # ä»æ–‡ä»¶è¯»å–ä¸»æœºåˆ—è¡¨
  %(prog)s --verbose                 # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        """
    )
    
    parser.add_argument(
        '-c', '--concurrent',
        type=int,
        default=10,
        help='æœ€å¤§å¹¶å‘æ•° (é»˜è®¤: 10)'
    )
    
    parser.add_argument(
        '-t', '--timeout',
        type=int,
        default=10,
        help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 10)'
    )
    
    parser.add_argument(
        '-q', '--query',
        type=str,
        default='test',
        help='æµ‹è¯•æŸ¥è¯¢å­—ç¬¦ä¸² (é»˜è®¤: test)'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)'
    )
    
    parser.add_argument(
        '--host-file',
        type=str,
        help='ä»æ–‡ä»¶è¯»å–ä¸»æœºåˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ª URLï¼‰'
    )
    
    parser.add_argument(
        '--use-tool',
        action='store_true',
        help='ä½¿ç”¨é¡¹ç›®çš„ searx å·¥å…·è¿›è¡Œæ£€æµ‹'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ›´æ–°é…ç½®æ–‡ä»¶'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—'
    )
    
    parser.add_argument(
        '--no-update',
        action='store_true',
        help='åªæ£€æµ‹ï¼Œä¸æ›´æ–°é…ç½®æ–‡ä»¶'
    )
    
    return parser.parse_args()


def load_hosts_from_file(file_path: str) -> List[str]:
    """
    ä»æ–‡ä»¶åŠ è½½ä¸»æœºåˆ—è¡¨
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        ä¸»æœº URL åˆ—è¡¨
    """
    hosts = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    hosts.append(line)
        logger.info(f"ä» {file_path} åŠ è½½äº† {len(hosts)} ä¸ªä¸»æœº")
        return hosts
    except Exception as e:
        logger.error(f"åŠ è½½ä¸»æœºæ–‡ä»¶å¤±è´¥: {e}")
        return []


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_arguments()
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print("ğŸš€ Searx å®ä¾‹å¯ç”¨æ€§æ£€æµ‹å™¨")
    print("="*60)
    print(f"é…ç½®: å¹¶å‘={args.concurrent}, è¶…æ—¶={args.timeout}s, æŸ¥è¯¢='{args.query}'")
    print(f"æ¨¡å¼: {'é¡¹ç›®å·¥å…·' if args.use_tool else 'ç›´æ¥HTTP'}")
    if args.dry_run:
        print("âš ï¸  æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - ä¸ä¼šä¿®æ”¹é…ç½®æ–‡ä»¶")
    print("="*60)
    
    # åŠ è½½ä¸»æœºåˆ—è¡¨
    if args.host_file:
        hosts = load_hosts_from_file(args.host_file)
        if not hosts:
            logger.error("æ— æ³•ä»æ–‡ä»¶åŠ è½½ä¸»æœºåˆ—è¡¨")
            return 1
    else:
        hosts = DEFAULT_HOST_LIST
    
    print(f"\nğŸ“‹ å‡†å¤‡æ£€æµ‹ {len(hosts)} ä¸ª Searx å®ä¾‹...")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    checker = SearxChecker(
        timeout=args.timeout,
        max_workers=args.concurrent,
        test_query=args.query,
        verbose=args.verbose
    )
    
    # æ‰§è¡Œæ£€æµ‹
    start_time = time.time()
    results = checker.check_hosts_concurrent(hosts, use_tool=args.use_tool)
    elapsed_time = time.time() - start_time
    
    # æ‰“å°ç»Ÿè®¡
    checker.print_summary(results)
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
    
    # è·å–å¯ç”¨çš„ä¸»æœº
    alive_hosts = [r.host for r in results if r.is_alive]
    
    if not alive_hosts:
        logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ Searx å®ä¾‹")
        return 1
    
    # æ›´æ–°é…ç½®æ–‡ä»¶
    if not args.no_update:
        config_manager = ConfigManager(args.config)
        success = config_manager.update_searx_hosts(alive_hosts, dry_run=args.dry_run)
        
        if not success and not args.dry_run:
            logger.error("âŒ æ›´æ–°é…ç½®æ–‡ä»¶å¤±è´¥")
            return 1
    else:
        print("\nè·³è¿‡é…ç½®æ–‡ä»¶æ›´æ–°ï¼ˆ--no-updateï¼‰")
    
    print(f"\nâœ¨ æ£€æµ‹å®Œæˆï¼æ‰¾åˆ° {len(alive_hosts)} ä¸ªå¯ç”¨å®ä¾‹")
    return 0


if __name__ == "__main__":
    sys.exit(main())